{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "6e8322dd-d216-45bc-ae73-abc59b0fc040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsm0D-Ugmvzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AlgAclcK2My",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIAVZzeGK4dJ",
        "colab_type": "code",
        "outputId": "d08fea2f-b3fe-4b21-bf5c-c161255e1a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from hn.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Splitting the data in train- and testpart with a portion of 'test_size' training data (20%)\n",
        "data_train, data_test = model_selection.train_test_split(data, test_size=0.20, stratify=data['label'])\n",
        "\n",
        "print(f'The number of rows of train data : {len(data_train.index)}')\n",
        "print(f'The number of rows of test data : {len(data_test.index)}')\n",
        "\n",
        "# seperate the data in features and tumorstage\n",
        "stage_train = data_train['label']          # dataframe containing tumor stadium of subject (T12/T34)\n",
        "stage_test = data_test['label'] \n",
        "data_train = data_train.drop(columns='label') # dataframe containing all feature columns except 'label' (tumor stadium of subject)\n",
        "data_test = data_test.drop(columns='label')\n",
        "\n",
        "# Binarize label data\n",
        "stage_train = preprocessing.label_binarize(stage_train, ['T12', 'T34'])\n",
        "stage_train = [i[0] for i in stage_train]\n",
        "\n",
        "stage_test = preprocessing.label_binarize(stage_test, ['T12', 'T34'])\n",
        "stage_test = [i[0] for i in stage_test]\n",
        "\n"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 113\n",
            "The number of columns: 160\n",
            "The number of rows of train data : 90\n",
            "The number of rows of test data : 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZUAiDtz5djl",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "- column verdwijnt als >25% van de column een 0 bevat. Dit heb ik gedaan omdat het vervangen van alle 0 voor NaN me niet heel handig leek, omdat je die 0 soms wel wilt gebruiken als het echt als waarde voorkomt.\n",
        "- we kunnen nog proberen om 'missende' waardes op te vullen met 'feature imputation' zoals besproken in het college van 26/03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "2ca11ce6-798d-412f-87c1-087828235dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Imputation\n",
        "#imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "#imp.fit(data_train)\n",
        "#data_train = imp.transform(data_train)\n",
        "#data_test = imp.transform(data_test)\n",
        "\n",
        "# Remove all columns where more than 25% of the values are 0.0\n",
        "drop_cols_train = data_train.columns[(data_train == 0).sum() > 0.25*data_train.shape[1]]\n",
        "drop_cols_test = data_test.columns[(data_train ==0).sum() > 0.25*data_train.shape[1]]\n",
        "data_train.drop(drop_cols_train, axis = 1, inplace = True) \n",
        "data_test.drop(drop_cols_test, axis = 1, inplace = True)\n",
        "print(f'The number of columns after preprocessing: {len(data_train.columns)}')\n",
        "print(f'The number of columns after preprocessing: {len(data_test.columns)}')\n",
        "\n",
        "\n",
        "# Remove all columns with no std\n",
        "drop_std_train = data_train.columns[data_train.std() == 0]\n",
        "drop_std_test = data_test.columns[data_train.std() == 0]\n",
        "data_train.drop(drop_std_train, axis = 1, inplace = True) \n",
        "data_test.drop(drop_std_test, axis = 1, inplace = True)\n",
        "\n",
        "print(f'TRAIN: The number of columns after preprocessing: {len(data_train.columns)}, and the number of rows: {len(data_train.index)}')\n",
        "print(f'TEST: The number of columns after preprocessing: {len(data_test.columns)},  and the number of rows: {len(data_test.index)}')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of columns after preprocessing: 152\n",
            "The number of columns after preprocessing: 152\n",
            "TRAIN: The number of columns after preprocessing: 150, and the number of rows: 90\n",
            "TEST: The number of columns after preprocessing: 150,  and the number of rows: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVOizcWl4sAM",
        "colab_type": "text"
      },
      "source": [
        "## Data Scaling\n",
        "\n",
        "Overwegen welk van de onderstaande het beste is voor onze data! \n",
        "\n",
        "StandardScaler removes the mean and scales the data to unit variance.  cannot guarantee balanced feature scales in the presence of outliers.\n",
        "\n",
        "MinMaxScaler rescales the data set such that all feature values are in the range [0, 1], very sensitive to outliers\n",
        "\n",
        "Robust scaler. Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers.\n",
        "\n",
        "Read more: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hKWuBpi4xck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data (train on train set)\n",
        "scaler = preprocessing.StandardScaler()   \n",
        "scaler.fit(data_train)  \n",
        "\n",
        "# Perform scaling on both train and testset\n",
        "data_train_scaled = scaler.transform(data_train)\n",
        "data_test_scaled = scaler.transform(data_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLXxyvuwqW7q",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection/extraction\n",
        "\n",
        "Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\n",
        "\n",
        "\n",
        "Variabelen\n",
        "- stratifiedKfold(x), x veranderen geeft hele andere uitkomsten\n",
        "- step = x, x laten als 1!\n",
        "\n",
        "! Dit gebruiken we nu nog niet\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV\n",
        "\n",
        "- Univariate testing: select best performing features based on statistical test: sklearn.feature_selection.SelectKBest()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe6OoqWjq0Ni",
        "colab_type": "code",
        "outputId": "a9b821c3-d32f-4c98-aae0-9d320e00b4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "# Recursive Feature Elimination\n",
        "svc = svm.SVC(kernel=\"linear\")  # Create the RFE object and compute a cross-validated score.\n",
        "\n",
        "# classifications\n",
        "rfecv = feature_selection.RFECV(\n",
        "    estimator=svc, step=1, \n",
        "    cv=model_selection.StratifiedKFold(4),\n",
        "    scoring='roc_auc')\n",
        "fit = rfecv.fit(data_train_scaled, stage_train)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n",
        "\n",
        "print(\"Num Features: %d\" % fit.n_features_)\n",
        "print(\"Selected Features: %s\" % fit.support_)\n",
        "print(\"Feature Ranking: %s\" % fit.ranking_)\n"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP1ChE/OjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Num Features: 5\n",
            "Selected Features: [False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False  True  True False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False  True False False False False False False False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False  True False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False]\n",
            "Feature Ranking: [ 52 139  62 110 124 143  47  97  11  87  12 136 107  17  82  66  79  57\n",
            "   8  16  78  81  77  80   9 135  68  69  39  30  95  75  74  65 121 118\n",
            "  93 103 119  64  13   1   1 131  90 123  46  94 122  53  51  22  98  44\n",
            "  92 140  73  91  25 101  59 104 102  76   6  63  45 109 130 128 137  50\n",
            " 114  83  27 134 125  26  34 117 120  40 138  15   2  42   1  61  35  71\n",
            " 127  84  72  48  60  58  14  55  86 100  31   1 126 116 142  28 141  85\n",
            "  33   7  89  99 112 105 115  24  21  19  38  88   5   1  43   3  96  18\n",
            "  23  20  29  37  56   4  36  41  49 113  67  54 106 144  10 145 108  70\n",
            " 129 111  32 133 132]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-f-qvIbMvu2",
        "colab_type": "text"
      },
      "source": [
        "##  Feature selection using univariate feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GpfGpM1M4Dp",
        "colab_type": "code",
        "outputId": "b9ed2c0f-9d26-442b-f1b7-3313eac66bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "from sklearn import feature_selection\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.feature_selection import f_classif\n",
        "# X_new = SelectKBest(chi2, k=50).fit_transform(stage_train, data_train_scaled)\n",
        "# print(X_new.shape)\n",
        "\n",
        "selector = SelectPercentile(f_classif, percentile=10)\n",
        "fit = selector.fit(data_train_scaled, stage_train)\n",
        "\n",
        "print(\"Feature Ranking: %s\" % fit.scores_)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Ranking: [2.81789176e+01 2.56640345e+01 7.00253922e+00 6.46980004e-01\n",
            " 1.59524571e+00 8.49876228e-01 2.91408169e+00 2.20111596e+01\n",
            " 1.28115175e+01 1.71335424e+00 5.86104889e-02 3.92029970e-01\n",
            " 1.68799833e-01 1.84032256e+00 3.16886972e+00 5.27773266e-02\n",
            " 5.92675057e+00 3.54695983e+00 3.36641612e+00 5.30948468e+00\n",
            " 3.62131390e-01 1.38386956e+00 7.94835735e-01 7.76628851e+00\n",
            " 5.20357149e+00 3.11858902e+01 1.44408821e+01 1.54913610e+00\n",
            " 1.35588575e+01 7.93693261e-01 2.16970781e+00 1.41280414e+01\n",
            " 3.02670592e+01 1.62148701e-01 4.86767147e+00 1.75775598e+01\n",
            " 1.21161506e+01 1.12140461e+01 4.86767147e+00 4.31797739e+01\n",
            " 2.97965784e+01 2.66232825e+01 3.32915587e+01 2.61129976e+01\n",
            " 1.84718862e+01 3.65580027e-01 1.55922931e+01 3.65021014e+00\n",
            " 2.30070558e+00 1.14799086e+00 4.61681325e+00 2.64431758e+00\n",
            " 7.51521828e+00 1.14799086e+00 1.16295291e+00 5.16139744e+00\n",
            " 2.74709879e+00 2.74639935e+00 2.74727366e+00 5.90873699e+00\n",
            " 1.23717458e+01 9.78880865e+00 1.07218951e+00 7.08749080e-03\n",
            " 4.09307132e+00 2.47383570e+00 1.67979899e+00 1.55266966e+00\n",
            " 4.11370096e-01 9.26720229e+00 1.16938594e-01 3.80462288e+00\n",
            " 7.13827546e+00 1.55151439e+01 4.04208233e+00 5.14219298e+00\n",
            " 3.95009349e+00 6.93459013e+00 5.69832877e+00 4.24475311e+00\n",
            " 1.43585549e+01 9.69056797e+00 5.13568797e+00 9.39211942e+00\n",
            " 3.82089937e+00 1.21753008e+01 1.71292356e+00 4.92221974e+00\n",
            " 2.15545811e-01 6.70792006e+00 2.88392484e-03 3.80696704e+00\n",
            " 1.16569142e+01 1.82768540e+00 7.91340335e+00 6.57225517e+00\n",
            " 1.70464803e+00 1.43210935e+01 3.94152101e-01 3.32246578e-02\n",
            " 2.88375572e+00 5.28120380e+00 1.13502291e+00 7.29191706e+00\n",
            " 1.61551528e+01 9.85819246e+00 7.11067980e+00 1.19937568e+01\n",
            " 1.50224083e+00 3.95029704e-01 9.08093457e-02 1.18906714e+00\n",
            " 5.68030355e-01 5.07166275e+00 9.19430591e-01 2.16843313e+00\n",
            " 3.08513529e-01 1.05180806e-01 5.41584215e-01 1.20031809e-01\n",
            " 7.20304575e+00 2.44222537e+01 7.97474566e+00 3.71169474e+00\n",
            " 1.41470325e+01 2.13378445e+01 1.38199616e+01 2.66270219e+01\n",
            " 3.20376930e+01 1.73731281e+01 2.90048030e+01 2.56738351e+01\n",
            " 5.08822017e+00 5.90342848e+00 2.11109458e+01 1.44986214e+00\n",
            " 1.11170370e+00 7.88740344e+00 5.08095039e-02 9.56049383e-01\n",
            " 4.00694935e-01 9.56049383e-01 5.97363405e+00 7.33673988e+00\n",
            " 7.81189167e-02 6.31950826e+00 1.49842869e+01 7.03947106e-01\n",
            " 4.69890002e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W29ecNuDM1Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o251HvpzBy4l",
        "colab_type": "text"
      },
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "- nu voor eerste 20 features, bedenken hoe veel we er willen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4IiEnXmB-Y3",
        "colab_type": "code",
        "outputId": "74584ee5-c449-4cfb-c1aa-da89aaceee93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "# Create a function for calculating PCA\n",
        "def pca(data_train, data_test):\n",
        "    \"\"\"\n",
        "    Function for PCA\n",
        "\n",
        "        data_train = training data\n",
        "        data_test = testing data\n",
        "\n",
        "    Output is transformed train- and testdata\n",
        "    \"\"\"\n",
        "    pca=PCA().fit(data_train)\n",
        "    var = np.cumsum(pca.explained_variance_ratio_)\n",
        "    n_comp = np.where(var>0.99)[0][0]\n",
        "\n",
        "    # Create and fit a PCA with 20 components\n",
        "    pca_train = PCA(n_components=n_comp)\n",
        "    pca_train.fit(data_train)\n",
        "\n",
        "    # Transform data using PCA\n",
        "    data_train_trans = pca_train.transform(data_train)\n",
        "    data_test_trans = pca_train.transform(data_test)\n",
        "\n",
        "    # Return transformed train- and testdata\n",
        "    return data_train_trans, data_test_trans\n",
        "\n",
        "data_train_pca, data_test_pca = pca(data_train_scaled, data_test_scaled)\n",
        "print(data_train_pca.shape)\n",
        "print(data_test_pca.shape)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 56)\n",
            "(23, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BuHDPdnIoXx",
        "colab_type": "text"
      },
      "source": [
        "## kNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaokGZwe7zDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "468c0dce-fec6-4ba1-9b9b-0fb1daef32b1"
      },
      "source": [
        "# List with hyperparameters that we want to tune.\n",
        "leaf_size = list(range(1,50))\n",
        "n_n = list(range(1,50))\n",
        "p=[1,2]\n",
        "weights = ['uniform', 'distance']\n",
        "\n",
        "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_n, p=p, weights = weights)\n",
        "\n",
        "# Create new KNN object\n",
        "knn_tune = neighbors.KNeighborsClassifier()\n",
        "\n",
        "# Use Randomized Search\n",
        "# Als je GridSearch gebruikt, komt er telkens hetzelfde uit. \n",
        "clf_tune_knn = model_selection.RandomizedSearchCV(knn_tune, hyperparameters, n_iter = 30, cv=10, random_state = 42)\n",
        "# Random state mag vgm niet, maar is de enige manier om ervoor te zorgen dat het constant dezelfde output geeft\n",
        "\n",
        "#Fit the model\n",
        "best_model = clf_tune_knn.fit(data_train_pca, stage_train)\n",
        "\n",
        "leaf_size_best = best_model.best_estimator_.get_params()['leaf_size']\n",
        "p_best = best_model.best_estimator_.get_params()['p']\n",
        "n_n_best = best_model.best_estimator_.get_params()['n_neighbors']\n",
        "weights_best = best_model.best_estimator_.get_params()['weights']\n",
        "\n",
        "\n",
        "#Print The value of best Hyperparameters\n",
        "print('Best leaf_size:', leaf_size_best)\n",
        "print('Best p:', p_best)\n",
        "print('Best n_neighbors:', n_n_best)\n",
        "print('Best weights:', weights_best)\n",
        "\n",
        "def knn_classifier(leaf_size, p, n_neigbors, weights, data_train, data_test, label_train, label_test):\n",
        "    \"\"\"\n",
        "    Function for kNN training and testing\n",
        "\n",
        "        data_train =  training data (type = list)\n",
        "        data_test_trans = testing data (type = list)\n",
        "        label_train = class of training data (type = list)\n",
        "        label_test = class of testing data (type = list)\n",
        "        \n",
        "    Output is two lists with the predicted class of the train- and testdata \n",
        "    \"\"\"\n",
        "    knn = neighbors.KNeighborsClassifier(leaf_size = leaf_size, weights = weights, n_neighbors = n_neigbors, p = p)\n",
        "    knn.fit(data_train, label_train)\n",
        "    label_train_knn = knn.predict(data_train)\n",
        "    label_test_knn = knn.predict(data_test)\n",
        "    score_train = knn.score(data_train, label_train)\n",
        "    score_test = knn.score(data_test, label_test)\n",
        "    return score_train, score_test, label_train_knn, label_test_knn\n",
        "\n",
        "score_train_knn, score_test_knn, stage_train_knn, stage_test_knn = knn_classifier(leaf_size_best, p_best, n_n_best, weights_best, data_train_pca, data_test_pca, stage_train, stage_test)\n",
        "print(f'Accuracy of classifier on traindata: {score_train_knn}') # accuracy\n",
        "print(f'Accuracy of classifier on testdata: {score_test_knn}') # accuracy\n"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best leaf_size: 11\n",
            "Best p: 2\n",
            "Best n_neighbors: 22\n",
            "Best weights: distance\n",
            "Accuracy of classifier on traindata: 1.0\n",
            "Accuracy of classifier on testdata: 0.6956521739130435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bs85wHUxnqA",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machine (SVM)\n",
        "-  Geeft nu alleen een kernel mee, maar heeft nog veel meer parameters\n",
        "- test_decision = svc.decision_function(data_test) kunnen we later miss nog gebruiken om een ROC te maken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-mVIOLhxpsJ",
        "colab_type": "code",
        "outputId": "2444feff-d2dd-422d-ed7d-21eaead3e5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# List with hyperparameters that we want to tune.\n",
        "kernels = ['linear', 'poly', 'rbf']\n",
        "gammas = [0.1, 1, 10, 100]\n",
        "cs = [0.1, 1, 10, 100, 1000]\n",
        "degrees = [0, 1, 2, 3, 4, 5, 6] # use only for 'poly'\n",
        "\n",
        "hyperparameters = dict(kernel = kernels, gamma = gammas, C = cs, degree = degrees  )\n",
        "\n",
        "# Create new KNN object\n",
        "svm_tune = svm.SVC()\n",
        "\n",
        "# Use Randomized Search\n",
        "# Als je GridSearch gebruikt, komt er telkens hetzelfde uit. \n",
        "clf_tune_svm = model_selection.RandomizedSearchCV(svm_tune, hyperparameters, n_iter = 30, cv=10)\n",
        "\n",
        "\n",
        "#Fit the model\n",
        "best_model_svm = clf_tune_svm.fit(data_train_pca, stage_train)\n",
        "\n",
        "kernel_best = best_model_svm.best_estimator_.get_params()['kernel']\n",
        "gamma_best = best_model_svm.best_estimator_.get_params()['gamma']\n",
        "c_best = best_model_svm.best_estimator_.get_params()['C']\n",
        "degree_best = best_model_svm.best_estimator_.get_params()['degree']\n",
        "\n",
        "#Print The value of best Hyperparameters\n",
        "print('Best kernel:', kernel_best)\n",
        "print('Best gamma:', gamma_best)\n",
        "print('Best C:', c_best)\n",
        "print('Best degree:', degree_best)\n",
        "\n",
        "\n",
        "def svm_classifier(C, kernel, degree, gamma, data_train, data_test, label_train, label_test, svm_kernel):\n",
        "    \"\"\"\n",
        "    Function for SVM training and testing\n",
        "\n",
        "        data_train =  training data (type = list)\n",
        "        data_test_trans = testing data (type = list)\n",
        "        label_train = class of training data (type = list)\n",
        "        label_test = class of testing data (type = list)\n",
        "        svm_kernel = different kernels to be used (type = string)\n",
        "\n",
        "    Output is two lists with the predicted class of the train- and testdata\n",
        "    \"\"\"\n",
        "    svc = svm.SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)\n",
        "    svc.fit(data_train, label_train)\n",
        "\n",
        "    # Predict the classes of the data \n",
        "    label_train_svm = svc.predict(data_train)\n",
        "    label_test_svm= svc.predict(data_test)\n",
        "\n",
        "    score_train = svc.score(data_train, label_train)\n",
        "    score_test = svc.score(data_test, label_test)\n",
        "    \n",
        "    return label_train_svm, label_test_svm, score_train, score_test\n",
        "\n",
        "stage_train_svm, stage_test_svm, score_train_svm, score_test_svm = svm_classifier(c_best, kernel_best, degree_best, gamma_best, data_train_pca, data_test_pca, stage_train, stage_test, 'linear')\n",
        "print(f'Accuracy of classifier on traindata: {score_train_svm}') # accuracy\n",
        "print(f'Accuracy of classifier on testdata: {score_test_svm}') # accuracy"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best kernel: linear\n",
            "Best gamma: 1\n",
            "Best C: 10\n",
            "Best degree: 3\n",
            "Accuracy of classifier on traindata: 1.0\n",
            "Accuracy of classifier on testdata: 0.7391304347826086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1XtlFR3upM",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest Classifier \n",
        "- alle parameters nog bepalen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O760t93K3zWu",
        "colab_type": "code",
        "outputId": "d4d0312b-49c8-43f7-dd89-2da77b47da40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def rfc_classifier(data_train, data_test, label_train, label_test):\n",
        "    \"\"\"\n",
        "    Function for RFC training and testing\n",
        "\n",
        "        data_train =  training data (type = list)\n",
        "        data_test_trans = testing data (type = list)\n",
        "        label_train = class of training data (type = list)\n",
        "        label_test = class of testing data (type = list)\n",
        "        \n",
        "    Output is two lists with the predicted class of the train- and testdata \n",
        "    \"\"\"\n",
        "    # Create Random Forest Classifier and fit classifier on traindata\n",
        "    rfc = RandomForestClassifier(max_depth=2)\n",
        "    rfc.fit(data_train, label_train)\n",
        "\n",
        "    # Predict labels for train- and testdata\n",
        "    label_train_rfc = rfc.predict(data_train)\n",
        "    label_test_rfc = rfc.predict(data_test)\n",
        "\n",
        "    return label_train_rfc, label_test_rfc\n",
        "\n",
        "stage_train_rfc, stage_test_rfc = rfc_classifier(data_train_pca, data_test_pca, stage_train, stage_test)\n",
        "print(stage_test_rfc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSkNx_JkLzFi",
        "colab_type": "text"
      },
      "source": [
        "## Performance\n",
        "- Functie gemaakt om een dataframe te maken van de performance van een bepaalde classifier\n",
        "- Uiteindelijke mooier om alles er tegelijk in te kunnen gooien met een loop en dan 1 groot dataframe te maken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIUCuActMxr4",
        "colab_type": "code",
        "outputId": "33b7e733-baaa-4421-fae3-b5a0cc0d014f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "def performance_clf(predlabel_train, label_train, predlabel_test, label_test):\n",
        "    \"\"\"\n",
        "    Function to calculate performance of a classifier:\n",
        "\n",
        "        predlabel_train = predicted label of traindata \n",
        "        label_train = real label of traindata\n",
        "        predlabel_test = predicted label of testdata\n",
        "        label_test = real label of testdata\n",
        "    \n",
        "    This function returns a dataframe of the calculated AUC, accuracy, F1-score,\n",
        "    precision and recall of the classifier for the train- and testdata\n",
        "    \"\"\"\n",
        "    \n",
        "    # Performance train set\n",
        "    auc_train=metrics.roc_auc_score(predlabel_train, label_train)\n",
        "    accuracy_train=metrics.accuracy_score(predlabel_train, label_train)\n",
        "    F1_train=metrics.f1_score(predlabel_train, label_train)\n",
        "    precision_train=metrics.precision_score(predlabel_train, label_train)\n",
        "    recall_train=metrics.recall_score(predlabel_train, label_train)\n",
        "    \n",
        "    # Performance test set\n",
        "    auc_test=metrics.roc_auc_score(predlabel_test, label_test)\n",
        "    accuracy_test=metrics.accuracy_score(predlabel_test, label_test)\n",
        "    F1_test=metrics.f1_score(predlabel_test, label_test)\n",
        "    precision_test=metrics.precision_score(predlabel_test, label_test)\n",
        "    recall_test=metrics.recall_score(predlabel_test, label_test)\n",
        "\n",
        "    performance = {'train': [auc_train, accuracy_train, F1_train, precision_train, recall_train],\n",
        "                   'test': [auc_test, accuracy_test, F1_test, precision_test, recall_test]}\n",
        "    frame_performance = pd.DataFrame(data=performance, index=['auc', 'accuracy', 'F1', 'precision', 'recall'])\n",
        "  \n",
        "    return frame_performance\n",
        "\n",
        "performance_knn = performance_clf(stage_train_knn, stage_train, stage_test_knn, stage_test)\n",
        "performance_svm = performance_clf(stage_train_svm, stage_train, stage_test_svm, stage_test)\n",
        "performance_rfc = performance_clf(stage_train_rfc, stage_train, stage_test_rfc, stage_test)\n",
        "\n",
        "\n",
        "print(f'The performance of the kNN-classifier is: {performance_knn}')\n",
        "print(f'The performance of the SVM-classifier is: {performance_svm}')\n",
        "print(f'The performance of the RFC-classifier is: {performance_rfc}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The performance of the kNN-classifier is:               train      test\n",
            "auc        0.740642  0.777778\n",
            "accuracy   0.677778  0.652174\n",
            "F1         0.743363  0.714286\n",
            "precision  0.933333  1.000000\n",
            "recall     0.617647  0.555556\n",
            "The performance of the SVM-classifier is:               train      test\n",
            "auc        0.855731  0.780303\n",
            "accuracy   0.855556  0.782609\n",
            "F1         0.853933  0.761905\n",
            "precision  0.844444  0.800000\n",
            "recall     0.863636  0.727273\n",
            "The performance of the RFC-classifier is:               train      test\n",
            "auc        0.922431  0.707692\n",
            "accuracy   0.922222  0.695652\n",
            "F1         0.923077  0.695652\n",
            "precision  0.933333  0.800000\n",
            "recall     0.913043  0.615385\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
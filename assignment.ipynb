{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wsAK0KaohQVV",
        "u2PwNj7j1SFh",
        "-AlgAclcK2My",
        "oZUAiDtz5djl",
        "oVOizcWl4sAM",
        "BLXxyvuwqW7q",
        "5sZMD7Au7jsz",
        "QKWj0zjn2Qh8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maritverboom/TM10007_PROJECT/blob/master/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Group 15\n",
        "Bart Formsma: 4438450\n",
        "\n",
        "Eline van Lange: 4390210\n",
        "\n",
        "Laurien Reinders: 4472306\n",
        "\n",
        "Marit Verboom: 4453778\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "9c24189a-76a3-4dfe-f89a-8c077edd355c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsAK0KaohQVV",
        "colab_type": "text"
      },
      "source": [
        "## Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxz2ol8v3Kyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "# Feature selection methods\n",
        "from sklearn import feature_selection\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from yellowbrick.regressor import AlphaSelection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Statistics\n",
        "from statistics import mean\n",
        "from statistics import stdev\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from math import sqrt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PwNj7j1SFh",
        "colab_type": "text"
      },
      "source": [
        "## Function for learning curve in order te evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siRrGSGS1SR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Function to plot a StandardScaler.\n",
        "    Input:\n",
        "    - estimator: object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "    - title: string, title of the figure\n",
        "    - x: data_train\n",
        "    - y: data_stage\n",
        "    - axes: axes to use for plotting the curves\n",
        "    - ylim: minimum and maximum yvalues plotted\n",
        "    - cv: cross-validation generator\n",
        "    - n_jobs: number of jobs to run in parallel\n",
        "    - train_sizes: the test data that should be scaled\n",
        "    Output:\n",
        "    - Learning curve plot\n",
        "    \"\"\"\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores  =  model_selection.learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AlgAclcK2My",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading\n",
        "- Loading the provided Head & Neck dataset\n",
        "- Splitting the data in train- and testset\n",
        "- Binarizing tumor stages: TM12 = 0, TM34 = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIAVZzeGK4dJ",
        "colab_type": "code",
        "outputId": "cb4a5fe4-c2f3-4352-e435-4284deaa4c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Import dataset\n",
        "from hn.load_data import load_data\n",
        "data = load_data()\n",
        "data_start = data\n",
        "print(f'The number of samples (the patients): {len(data.index)}')\n",
        "print(f'The number of columns (the features): {len(data.columns)}')\n",
        "\n",
        "# Splitting the data in train- and testpart with a portion of 'test_size' testing data (20%)\n",
        "data_train, data_test = model_selection.train_test_split(data, test_size=0.20, stratify=data['label'])\n",
        "\n",
        "print(f'The number of samples of train data : {len(data_train.index)}')\n",
        "print(f'The number of samples of test data : {len(data_test.index)}')\n",
        "\n",
        "# dataframe containing tumor stadium of subject (T12/T34)\n",
        "stage_train = data_train['label']             \n",
        "stage_test = data_test['label'] \n",
        "\n",
        "# dataframe containing all feature columns except 'label' (tumor stadium of subject)\n",
        "data_train = data_train.drop(columns='label') \n",
        "data_test = data_test.drop(columns='label')\n",
        "\n",
        "# Binarize label data\n",
        "stage_train = preprocessing.label_binarize(stage_train, ['T12', 'T34'])\n",
        "stage_train = [i[0] for i in stage_train]\n",
        "stage_test = preprocessing.label_binarize(stage_test, ['T12', 'T34'])\n",
        "stage_test = [i[0] for i in stage_test]\n",
        "\n",
        "labels_T12_train = stage_train.count(0)\n",
        "labels_T12_test = stage_test.count(0)\n",
        "labels_T34_train = stage_train.count(1)\n",
        "labels_T34_test = stage_test.count(1)\n",
        "print(f'Train samples with label T12: {labels_T12_train}/{len(data_train.index)}, Test samples with label T12: {labels_T12_test}/{len(data_test.index)}, total number of samples with label T12: {labels_T12_train + labels_T12_test}/{len(data.index)}')\n",
        "print(f'Train samples with label T34: {labels_T34_train}/{len(data_train.index)}, Test samples with label T34: {labels_T34_test}/{len(data_test.index)}, total number of samples with label T34: {labels_T34_train + labels_T34_test}/{len(data.index)}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples (the patients): 113\n",
            "The number of columns (the features): 160\n",
            "The number of samples of train data : 90\n",
            "The number of samples of test data : 23\n",
            "Train samples with label T12: 46/90, Test samples with label T12: 12/23, total number of samples with label T12: 58/113\n",
            "Train samples with label T34: 44/90, Test samples with label T34: 11/23, total number of samples with label T34: 55/113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZUAiDtz5djl",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning\n",
        "- Removing columns where > 25% of the values are 0.0\n",
        "- Removing columns containing the same value for each sample\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "185d4433-d88a-4341-896d-50d1c623d5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Function for data cleaning\n",
        "def data_cleaning(data_train, data_test):\n",
        "    \"\"\"\n",
        "    Function for cleaning the data, by removing columns where >25% of the values are 0.0\n",
        "    and removing columns containing the same value for each sample.\n",
        "    Input:\n",
        "    - data_train: the train data that should be cleaned\n",
        "    - data_test: the test data that should be cleaned\n",
        "    Output:\n",
        "    - data_train: the cleaned train data\n",
        "    - data-test: the cleaned test data\n",
        "    \"\"\"\n",
        "    # Remove all columns where more than 25% of the values are 0.0\n",
        "    drop_cols_train = data_train.columns[(data_train == 0).sum() > 0.25*data_train.shape[1]]\n",
        "    drop_cols_test = data_test.columns[(data_train ==0).sum() > 0.25*data_train.shape[1]]\n",
        "    data_train.drop(drop_cols_train, axis = 1, inplace = True) \n",
        "    data_test.drop(drop_cols_test, axis = 1, inplace = True)\n",
        "    \n",
        "    # Remove all columns with no std\n",
        "    drop_std_train = data_train.columns[data_train.std() == 0]\n",
        "    drop_std_test = data_test.columns[data_train.std() == 0]\n",
        "    data_train.drop(drop_std_train, axis = 1, inplace = True) \n",
        "    data_test.drop(drop_std_test, axis = 1, inplace = True)\n",
        "    \n",
        "    return data_train, data_test\n",
        "\n",
        "# Apply data_cleaning to data_train and data_test in order to evaluate different scalers, feature selection methods and classifiers.\n",
        "data_train, data_test = data_cleaning(data_train, data_test)\n",
        "\n",
        "print(f'TRAIN: The number of columns after cleaning: {len(data_train.columns)}, and the number of rows: {len(data_train.index)}')\n",
        "print(f'TEST: The number of columns after cleaning: {len(data_test.columns)},  and the number of rows: {len(data_test.index)}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: The number of columns after cleaning: 150, and the number of rows: 90\n",
            "TEST: The number of columns after cleaning: 150,  and the number of rows: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVOizcWl4sAM",
        "colab_type": "text"
      },
      "source": [
        "## Data standard scaling\n",
        "\n",
        "- Scaling the train- and test dataset with a Standard Scaler\n",
        "- Scaling the train- and test dataset with a Robust Scaler\n",
        "- Scaling the train- and test dataset with a MinMax scaler\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttxbc58hrcPZ",
        "colab_type": "text"
      },
      "source": [
        "Scaling the train- and test dataset with a Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hKWuBpi4xck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_scaling(data_train, data_test):\n",
        "    \"\"\"\n",
        "    Function to scale the data using a StandardScaler.\n",
        "    Input:\n",
        "    - data_train: the train data that should be scaled\n",
        "    - data_test: the test data that should be scaled\n",
        "    Output:\n",
        "    - data_train_scaled: the standard scaled data\n",
        "    - data-test_scaled: the standard scaled data \n",
        "    \"\"\"\n",
        "    # Scale the data (train on train set)\n",
        "    scaler = preprocessing.StandardScaler()   \n",
        "    scaler.fit(data_train)  \n",
        "\n",
        "    # Perform scaling on both train and testset, returing scaled dataframe\n",
        "    data_train_scaled = pd.DataFrame(scaler.transform(data_train), columns = data_train.columns)\n",
        "    data_test_scaled = pd.DataFrame(scaler.transform(data_test), columns=data_test.columns) \n",
        "\n",
        "    return data_train_scaled, data_test_scaled\n",
        "\n",
        "# Apply data_scaling to data_train and data_test in order to evaluate different scalers, feature selection methods and classifiers.\n",
        "data_train_scaled, data_test_scaled = data_scaling(data_train, data_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erqy09vSvlnk",
        "colab_type": "text"
      },
      "source": [
        "Scaling the train- and test dataset with a Robust Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq4zowWRvn52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_scaling_robust(data_train, data_test):\n",
        "    \"\"\"\n",
        "    Function to scale the data using a RobustScaler.\n",
        "    Input:\n",
        "    - data_train: the train data that should be scaled\n",
        "    - data_test: the test data that should be scaled\n",
        "    Output:\n",
        "    - data_train_scaled_robust: the robust scaled data\n",
        "    - data-test_scaled_robust: the robust scaled data\n",
        "    \"\"\"\n",
        "    # Scale the data (train on train set)\n",
        "    scaler = preprocessing.RobustScaler()   \n",
        "    scaler.fit(data_train)  \n",
        "\n",
        "    # Perform scaling on both train and testset, returing scaled dataframe\n",
        "    data_train_scaled_robust = pd.DataFrame(scaler.transform(data_train), columns = data_train.columns)\n",
        "    data_test_scaled_robust = pd.DataFrame(scaler.transform(data_test), columns=data_test.columns) \n",
        "\n",
        "    return data_train_scaled_robust, data_test_scaled_robust\n",
        "\n",
        "# Apply data_scaling_robust to data_train and data_test in order to evaluate different scalers, feature selection methods and classifiers.\n",
        "data_train_scaled_robust, data_test_scaled_robust = data_scaling_robust(data_train, data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8qNv4G6kj-S",
        "colab_type": "text"
      },
      "source": [
        "Scaling the train- and test dataset with a MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jljXX2BRkkHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_scaling_MinMax(data_train, data_test):\n",
        "    \"\"\"\n",
        "    Function to scale the data using a MinMax Scaler.\n",
        "    Input:\n",
        "    - data_train: the train data that should be scaled\n",
        "    - data_test: the test data that should be scaled\n",
        "    Output:\n",
        "    - data_train_scaled_minmax: the standard scaled data\n",
        "    - data-test_scaled_minmax: the standard scaled data\n",
        "    \"\"\"\n",
        "    # Scale the data (train on train set)\n",
        "    scaler = preprocessing.MinMaxScaler()   \n",
        "    scaler.fit(data_train)  \n",
        "\n",
        "    # Perform scaling on both train and testset, returing scaled dataframe\n",
        "    data_train_scaled_minmax = pd.DataFrame(scaler.transform(data_train), columns = data_train.columns)\n",
        "    data_test_scaled_minmax = pd.DataFrame(scaler.transform(data_test), columns=data_test.columns) \n",
        "\n",
        "    return data_train_scaled_minmax, data_test_scaled_minmax\n",
        "\n",
        "# Apply data_scaling_MinMax to data_train and data_test in order to evaluate different scalers, feature selection methods and classifiers.\n",
        "data_train_scaled_minmax, data_test_scaled_minmax = data_scaling_MinMax(data_train, data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLXxyvuwqW7q",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection, elimination and transformation\n",
        "\n",
        "- Recursive Feature Elimination\n",
        "- Univariate Feature Selection\n",
        "- Principal Component Analysis\n",
        "- L1/Lasso Regression Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gxQOHHj9yMb",
        "colab_type": "text"
      },
      "source": [
        "Recursive Feature Elimination (rfecv)\n",
        "\n",
        "\n",
        "-   Evaluation of stability of rfecv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe6OoqWjq0Ni",
        "colab_type": "code",
        "outputId": "c9acada8-0bf8-4c04-c3be-c4754d186881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# Create the RFE object\n",
        "svc = svm.SVC(kernel=\"linear\")  \n",
        "\n",
        "# classifications\n",
        "rfecv = feature_selection.RFECV(\n",
        "    estimator=svc, step=1, \n",
        "    cv=model_selection.StratifiedKFold(4),\n",
        "    scoring='roc_auc')\n",
        "fit_rfecv = rfecv.fit(data_train_scaled, stage_train)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n",
        "\n",
        "print(\"Num Features: %d\" % fit_rfecv.n_features_)\n",
        "\n",
        "data_train_rfecv = rfecv.transform(data_train_scaled)\n",
        "data_test_rfecv = rfecv.transform(data_test_scaled)\n",
        "\n",
        "# Evaluating stability RFECV by running it 5 times using a different train-test split\n",
        "number_features_selected = []\n",
        "for _ in range(10):\n",
        "    # Splitting the data in train- and testpart with a portion of 'test_size' testing data (20%)\n",
        "    data_train, data_test = model_selection.train_test_split(data, test_size=0.20, stratify=data['label'])\n",
        "\n",
        "    stage_train = data_train['label']             \n",
        "    stage_test = data_test['label'] \n",
        "\n",
        "    data_train = data_train.drop(columns='label') \n",
        "    data_test = data_test.drop(columns='label')\n",
        "\n",
        "    stage_train = preprocessing.label_binarize(stage_train, ['T12', 'T34'])\n",
        "    stage_train = [i[0] for i in stage_train]\n",
        "    stage_test = preprocessing.label_binarize(stage_test, ['T12', 'T34'])\n",
        "    stage_test = [i[0] for i in stage_test]\n",
        "\n",
        "    data_train, data_test = data_cleaning(data_train, data_test)\n",
        "    data_train, data_tst = data_scaling(data_train, data_test)\n",
        "\n",
        "    fit_rfecv = rfecv.fit(data_train_scaled, stage_train)\n",
        "\n",
        "    number_features_selected.append(fit_rfecv.n_features_)\n",
        "print(f'Numbers of features selected each run: {number_features_selected}')\n",
        "\n",
        "print(f'\\nConclusion: the number of features selected after each run differs such much, that the RFECV as method for feature elimination is unstable')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Num Features: 12\n",
            "Numbers of features selected each run: [5, 12, 4, 37, 1, 5, 28, 40, 3, 29]\n",
            "\n",
            "Conclusion: the number of features selected after each run differs such much, that the RFECV as method for feature elimination is unstable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-f-qvIbMvu2",
        "colab_type": "text"
      },
      "source": [
        "Feature selection using univariate feature selection\n",
        "- Function to perform univariate feature selection on data\n",
        "- Evaluation of stability of univariate feature selection\n",
        "- Learning curve to determine which percentage for univariate feature selection should be taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GpfGpM1M4Dp",
        "colab_type": "code",
        "outputId": "d597664f-1946-42f3-e8f0-7367c6d6fd2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "source": [
        "# Function to apply univariate feature selection to data_train and data_test\n",
        "def uni(data_train, data_test, stage_train, percentile):\n",
        "    \"\"\"\n",
        "    Function to perform univariate feature selection \n",
        "    input:\n",
        "    - data_train: train data that should be transformed by univariate feature selection, which will be trained on this train data\n",
        "    - data-test: test data that should be transformed by univariate feature selection\n",
        "    - percentile: the percentage of the best predicting features that should be used\n",
        "    output:\n",
        "    - data_train_uni: transformed train dataset by univariate feature selection trained on train data\n",
        "    - data_test_uni: transformed test dataset by univariate feature selection trained on train data\n",
        "    \"\"\"\n",
        "    # Train univariate feature selection on train data\n",
        "    selector_uni = SelectPercentile(f_classif, percentile)\n",
        "    selector_uni.fit(data_train, stage_train)\n",
        "\n",
        "    # Transform data using univariate feature selection\n",
        "    data_train_uni = selector_uni.transform(data_train)\n",
        "    data_test_uni = selector_uni.transform(data_test)\n",
        "    \n",
        "    # Return transformed data\n",
        "    return data_train_uni, data_test_uni\n",
        "\n",
        "# Apply univariate feature selection function to data_train and data_test in order to evaluate different feature selection methods and classifiers.\n",
        "data_train_uni, data_test_uni = uni(data_train, data_test, stage_train, 20)\n",
        "\n",
        "# Evaluation univariate feature selection as feature selection method on dataset\n",
        "selector_uni = SelectPercentile(f_classif, 20)\n",
        "selector_uni.fit(data_train, stage_train)\n",
        "dfscores = pd.DataFrame(selector_uni.scores_)\n",
        "dfcolumns = pd.DataFrame(data_train.columns)\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score'] \n",
        "print(featureScores.nlargest(int(0.2*len(featureScores)),'Score'))  #print 40 best features\n",
        "\n",
        "print('\\nConclusion: running the univariate feature selection method for different train-test splits results in around the same top features selected, thus this method is stable and will be further processed and trained.')\n",
        "\n",
        "# Evaluating what percentage of features needs to be selected, using a learning curve\n",
        "perc = [20, 40, 60, 80, 100] # the evaluated percentages\n",
        "svm_scaler = svm.SVC() # evaluating is done using a svm classifier\n",
        "svm_scaler.fit(data_train_uni, stage_train)\n",
        "fig = plt.figure(figsize=(24,15))\n",
        "num = 0   \n",
        "cvlc = model_selection.StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "\n",
        "for per in perc:\n",
        "    data_train_uni, stage_train_uni  = uni(data_train, data_test, stage_train, per)\n",
        "    title = str(per)\n",
        "    ax = fig.add_subplot(5, 5, num + 1)\n",
        "    plot_learning_curve(svm_scaler, title, data_train_uni, stage_train, ax, ylim=(0.3, 1.01), cv=cvlc)\n",
        "    num += 1\n",
        "print(f'\\nConclusion: the chosen percentage of best predicting features using univariate feature selection is 20%, since otherwise the model is more prone to overfitting according to the learning curve')\n",
        "\n",
        "print(f'\\nLearning curve univariate feature selection and SVM classifier:')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                         Specs      Score\n",
            "39                         tf_GLRLM_RunEntropy  35.464108\n",
            "42                      tf_GLRLM_RunPercentage  27.733937\n",
            "132                      tf_Gabor_0.5A2.36skew  27.353797\n",
            "1                                   hf_entropy  26.119537\n",
            "32             tf_GLRLM_GrayLevelNonUniformity  25.725909\n",
            "25                          sf_rad_dist_avg_2D  23.427749\n",
            "0                                    hf_energy  22.923704\n",
            "41   tf_GLRLM_RunLengthNonUniformityNormalized  22.811033\n",
            "7                                      hf_peak  22.769827\n",
            "40             tf_GLRLM_RunLengthNonUniformity  22.763041\n",
            "43                        tf_GLRLM_RunVariance  22.331339\n",
            "129                       tf_Gabor_0.5A2.36max  21.953194\n",
            "128                      tf_Gabor_0.5A2.36kurt  20.254930\n",
            "135                     tf_LBP_kurtosis_R3_P12  19.210326\n",
            "131                       tf_Gabor_0.5A2.36min  16.878351\n",
            "126                      tf_Gabor_0.5A1.57skew  16.550643\n",
            "44                   tf_GLRLM_ShortRunEmphasis  16.495489\n",
            "28                         sf_roughness_std_2D  16.215438\n",
            "35                    tf_GLRLM_LongRunEmphasis  14.686796\n",
            "122                      tf_Gabor_0.5A1.57kurt  14.550480\n",
            "46       tf_GLRLM_ShortRunLowGrayLevelEmphasis  14.201456\n",
            "31                                sf_volume_2D  13.941862\n",
            "26                          sf_rad_dist_std_2D  13.860144\n",
            "127                       tf_Gabor_0.5A1.57std  13.834991\n",
            "130                      tf_Gabor_0.5A2.36mean  13.773648\n",
            "147                          tf_LBP_std_R3_P12  12.703618\n",
            "74                      tf_Gabor_0.05A1.57kurt  11.856634\n",
            "105                       tf_Gabor_0.2A2.36max  11.512512\n",
            "8                            hf_quartile_range  11.434645\n",
            "98                       tf_Gabor_0.2A1.57kurt  11.140021\n",
            "\n",
            "Conclusion: running the univariate feature selection method for different train-test splits results in around the same top features selected, thus this method is stable and will be further processed and trained.\n",
            "\n",
            "Conclusion: the chosen percentage of best predicting features using univariate feature selection is 20%, since otherwise the model is more prone to overfitting according to the learning curve\n",
            "\n",
            "Learning curve univariate feature selection and SVM classifier:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o251HvpzBy4l",
        "colab_type": "text"
      },
      "source": [
        "Principal Component Analysis (PCA)\n",
        "- Function to perform PCA on data\n",
        "- Evaluation of stability of PCA (using a standard scaler for preprocessing the data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4IiEnXmB-Y3",
        "colab_type": "code",
        "outputId": "27c9bcfa-7391-4a89-88ca-c8718a092658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Function to apply PCA to data_train and data_test\n",
        "def pca_opt(data_train, data_test):\n",
        "    \"\"\"\n",
        "    Function to perform PCA\n",
        "    input:\n",
        "    - data_train: train data that should be transformed by PCA, which will be trained on this train data\n",
        "    - data-test: test data that should be transformed by PCA\n",
        "    output:\n",
        "    - data_train: transformed train dataset by PCA trained on train data\n",
        "    - data_test: transformed test dataset by PCA trained on train data\n",
        "    \"\"\"\n",
        "    pca=PCA().fit(data_train)\n",
        "\n",
        "    # Amount of n-components based on a variance level of 0.99\n",
        "    var = np.cumsum(pca.explained_variance_ratio_)\n",
        "    n_comp = np.where(var>0.99)[0][0]\n",
        "    pca_train = PCA(n_components=n_comp)\n",
        "    pca_train.fit(data_train)\n",
        "\n",
        "    # Transform data using PCA\n",
        "    data_train = pca_train.transform(data_train)\n",
        "    data_test = pca_train.transform(data_test)\n",
        "\n",
        "    # Return transformed train- and testdata\n",
        "    return data_train, data_test\n",
        "\n",
        "# Apply PCA function to data_train and data_test in order to evaluate different feature selection methods and classifiers.\n",
        "data_train_pca, data_test_pca = pca_opt(data_train_scaled, data_test_scaled)\n",
        "\n",
        "# Evaluation stability of PCA as feature selection method on dataset\n",
        "number_of_components = []\n",
        "for _ in range(10):\n",
        "    # Splitting the data in train- and testpart with a portion of 'test_size' testing data (20%)\n",
        "    data_train, data_test = model_selection.train_test_split(data, test_size=0.20, stratify=data['label'])\n",
        "\n",
        "    stage_train = data_train['label']             \n",
        "    stage_test = data_test['label'] \n",
        "\n",
        "    data_train = data_train.drop(columns='label') \n",
        "    data_test = data_test.drop(columns='label')\n",
        "\n",
        "    stage_train = preprocessing.label_binarize(stage_train, ['T12', 'T34'])\n",
        "    stage_train = [i[0] for i in stage_train]\n",
        "    stage_test = preprocessing.label_binarize(stage_test, ['T12', 'T34'])\n",
        "    stage_test = [i[0] for i in stage_test]\n",
        "\n",
        "    data_train, data_test = data_cleaning(data_train, data_test)\n",
        "    data_train_scaled_standard, data_test_scaled_standard = data_scaling(data_train, data_test)\n",
        "    data_train_pca_standard, data_test_pca_standard = pca_opt(data_train_scaled_standard, data_test_scaled_standard)\n",
        "    number_of_components.append(data_train_pca_standard.shape[1])\n",
        "\n",
        "print(f'Numbers of components selected each run: {number_of_components}')\n",
        "\n",
        "print(f'\\nConclusion: the number of components selected after each run is 55 or 56, which means the PCA is stable on our data and will be further processed and trained.')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbers of components selected each run: [55, 55, 57, 55, 55, 56, 55, 55, 55, 55]\n",
            "\n",
            "Conclusion: the number of components selected after each run is 55 or 56, which means the PCA is stable on our data and will be further processed and trained.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCbyt5gGH0hd",
        "colab_type": "text"
      },
      "source": [
        "Lasso feature selection\n",
        "- Function to perform lasso feature selection\n",
        "- Evaluation of stability of the alpha parameter in lasso feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xJCUlNH01p",
        "colab_type": "code",
        "outputId": "a9ef5264-ae7e-4742-c54b-f7061ccf0cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "# Function to apply PCA to data_train and data_test\n",
        "def lasso_func(n_alphas, lasso, data_train, stage_train, data_test):\n",
        "    \"\"\"\n",
        "    Function to perform L1 feature selection\n",
        "    \"\"\"\n",
        "    # Determine optimal alpha\n",
        "    alphas = np.logspace(-1.5, -0.1, n_alphas)\n",
        "    hyperparameters_l1 = [{'alpha': alphas}]\n",
        "    n_folds = 5\n",
        "    clf = GridSearchCV(lasso, hyperparameters_l1, cv=n_folds, refit=False)\n",
        "    model_l1 = LassoCV(alphas = alphas)\n",
        "    alpha_best = model.alpha_\n",
        "\n",
        "    # Training Lasso on train data\n",
        "    selector_l1 = SelectFromModel(estimator=Lasso(alpha=alpha_best, random_state = 42))\n",
        "    selector_l1.fit(data_train, stage_train)\n",
        "\n",
        "    # Transform data_train and data_set by applying the selector\n",
        "    data_train_l1 = selector_l1.transform(data_train)\n",
        "    data_test_l1 = selector_l1.transform(data_test)\n",
        "\n",
        "    # Scores\n",
        "    scores = clf.cv_results_['mean_test_score']\n",
        "    scores_std = clf.cv_results_['std_test_score']\n",
        "\n",
        "    # Plot\n",
        "    plt.figure().set_size_inches(8, 6)\n",
        "    plt.semilogx(alphas, scores)\n",
        "    # plot error lines showing +/- std. errors of the scores\n",
        "    std_error = scores_std / np.sqrt(n_folds)\n",
        "    plt.semilogx(alphas, scores + std_error, 'b--')\n",
        "    plt.semilogx(alphas, scores - std_error, 'b--')\n",
        "    plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
        "    plt.ylabel('CV score +/- std error')\n",
        "    plt.xlabel('alpha')\n",
        "    plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
        "    plt.xlim([alphas[0], alphas[-1]])\n",
        "    n_selected = data_train_l1.shape[1]\n",
        "    \n",
        "\n",
        "    # Return transformed data_train and data_test and a plot\n",
        "    return data_train_l1, data_test_l1, n_selected, alpha_best, plt\n",
        "\n",
        "\n",
        "\n",
        "lasso = Lasso(max_iter=10000)\n",
        "n_alphas = 200\n",
        "# tuned_parameters = [{'alpha': alphas}]\n",
        "# n_folds = 5\n",
        "# clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=False)\n",
        "# clf.fit(data_train_scaled, stage_train)\n",
        "\n",
        "data_train_l1, data_test_l1, n_selected, alpha_best, plt = lasso_func(n_alphas, lasso, data_train, stage_train, data_test)\n",
        "\n",
        "print(f'The optimal alpha = {alpha_best}')\n",
        "# n_original = data_train_scaled.shape[1]\n",
        "print(f'\\nSelected {n_selected} from {n_original} features.')\n",
        "\n",
        "# Instantiate the linear model and visualizer\n",
        "# model = LassoCV(alphas=alphas)\n",
        "# visualizer = AlphaSelection(model)\n",
        "# visualizer.fit(data_train_scaled, stage_train)\n",
        "#visualizer.show()\n",
        "\n",
        "# alpha_best = model.alpha_\n",
        "# print(f'The optimal alpha = {alpha_best}')\n",
        "\n",
        "\n",
        "\n",
        "# selector = SelectFromModel(estimator=Lasso(alpha=alpha_best, random_state = 42))\n",
        "# selector.fit(data_train_scaled, stage_train)\n",
        "# n_original = data_train_scaled.shape[1]\n",
        "# data_train_l1 = selector.transform(data_train_scaled)\n",
        "# data_test_l1 = selector.transform(data_test_scaled)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-eb36464b502b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# clf.fit(data_train_scaled, stage_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdata_train_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasso_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_alphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The optimal alpha = {alpha_best}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-eb36464b502b>\u001b[0m in \u001b[0;36mlasso_func\u001b[0;34m(n_alphas, lasso, data_train, stage_train, data_test)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0malpha_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Training Lasso on train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LassoCV' object has no attribute 'alpha_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sZMD7Au7jsz",
        "colab_type": "text"
      },
      "source": [
        "## Selecting the best scaler based on stability on selecting components of PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-_M5S2S7j8G",
        "colab_type": "code",
        "outputId": "ab61cfd5-178b-4684-da3c-fff71a60fabf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "data_train_pca_standard_components = []\n",
        "data_train_pca_robust_components = []\n",
        "data_train_pca_minmax_components = []\n",
        "\n",
        "for _ in range(100):\n",
        "    # Splitting the data in train- and testpart with a portion of 'test_size' testing data (20%)\n",
        "    data_train, data_test = model_selection.train_test_split(data, test_size=0.20, stratify=data['label'])\n",
        "\n",
        "    stage_train = data_train['label']             \n",
        "    stage_test = data_test['label'] \n",
        "\n",
        "    data_train = data_train.drop(columns='label') \n",
        "    data_test = data_test.drop(columns='label')\n",
        "\n",
        "    stage_train = preprocessing.label_binarize(stage_train, ['T12', 'T34'])\n",
        "    stage_train = [i[0] for i in stage_train]\n",
        "    stage_test = preprocessing.label_binarize(stage_test, ['T12', 'T34'])\n",
        "    stage_test = [i[0] for i in stage_test]\n",
        "\n",
        "    data_train, data_test = data_cleaning(data_train, data_test)\n",
        "\n",
        "    # Selection of the scaler by comparing the mean componentens selected in PCA and its standard deviation\n",
        "    data_train_scaled_standard, data_test_scaled_standard = data_scaling(data_train, data_test)\n",
        "    data_train_scaled_robust, data_test_scaled_robust = data_scaling_robust(data_train, data_test)\n",
        "    data_train_scaled_minmax, data_test_scaled_minmax = data_scaling_MinMax(data_train, data_test)\n",
        "\n",
        "    data_train_pca_standard, data_test_pca_standard = pca_opt(data_train_scaled_standard, data_test_scaled_standard)\n",
        "    data_train_pca_standard_components.append(data_train_pca_standard.shape[1])\n",
        "    data_train_pca_robust, data_test_pca_robust = pca_opt(data_train_scaled_robust, data_test_scaled_robust)\n",
        "    data_train_pca_robust_components.append(data_train_pca_robust.shape[1])\n",
        "    data_train_pca_minmax, data_test_pca_minmax = pca_opt(data_train_scaled_minmax, data_test_scaled_minmax)\n",
        "    data_train_pca_minmax_components.append(data_train_pca_minmax.shape[1])\n",
        "\n",
        "print(data_train_pca_standard_components)\n",
        "data_train_pca_standard_mean_components = mean(data_train_pca_standard_components)\n",
        "data_train_pca_standard_stdev_components = stdev(data_train_pca_standard_components)\n",
        "data_train_pca_robust_mean_components = mean(data_train_pca_robust_components)\n",
        "data_train_pca_robust_stdev_components = stdev(data_train_pca_robust_components)\n",
        "data_train_pca_minmax_mean_components = mean(data_train_pca_minmax_components)\n",
        "data_train_pca_minmax_stdev_components = stdev(data_train_pca_minmax_components)\n",
        "\n",
        "print(f'The mean of the components in PCA selected using standard scalar is: {data_train_pca_standard_mean_components} with standard deviation: {data_train_pca_standard_stdev_components}')\n",
        "print(f'The mean of the components in PCA selected using robust scalar is: {data_train_pca_robust_mean_components} with standard deviation: {data_train_pca_robust_stdev_components}')\n",
        "print(f'The mean of the components in PCA selected using MinMax scalar is: {data_train_pca_minmax_mean_components} with standard deviation: {data_train_pca_minmax_stdev_components}')\n",
        "\n",
        "print(f'\\nConclusion: no major differences between the standard deviation for standard and MinMax scaler, but standard scaler is slightly better, so used as scaler from now on.')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[56, 54, 55, 55, 55, 55, 54, 55, 56, 55, 55, 55, 56, 56, 56, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 55, 56, 55, 56, 55, 55, 55, 56, 55, 56, 56, 55, 55, 55, 54, 55, 55, 55, 56, 56, 56, 55, 56, 56, 55, 55, 55, 55, 56, 55, 55, 56, 55, 55, 55, 56, 55, 55, 56, 55, 55, 56, 55, 55, 55, 55, 55, 55, 56, 55, 56, 55, 56, 55, 55, 55, 56, 55, 55, 56, 55, 55, 55, 56, 55, 55, 56, 56, 55, 55, 56, 55, 55, 55, 55]\n",
            "The mean of the components in PCA selected using standard scalar is: 55.31 with standard deviation: 0.5259911279353167\n",
            "The mean of the components in PCA selected using robust scalar is: 43.29 with standard deviation: 5.158683960277098\n",
            "The mean of the components in PCA selected using MinMax scalar is: 52.36 with standard deviation: 0.5416025603090641\n",
            "\n",
            "Conclusion: no major differences between the standard deviation for standard and MinMax scaler, but standard scaler is slightly better, so used as scaler from now on.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKWj0zjn2Qh8",
        "colab_type": "text"
      },
      "source": [
        "## Classifier functions, including optimization\n",
        "- k-nearest neighbors (k-NN)\n",
        "- Support Vector Machine (SVM)\n",
        "- Random Forest (RF)\n",
        "- Neural Network (NN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKVMSxv1Nd4G",
        "colab_type": "text"
      },
      "source": [
        "k-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiMfkWwc2Uxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn_class(data_train, data_test, stage_train, stage_test):\n",
        "    \"\"\"\n",
        "    Function for performing the k-NN classifier\n",
        "    and optimization of the k-NN algorithm hyperparameters:\n",
        "      - n_neighbours\n",
        "      - leaf_size\n",
        "    input:\n",
        "      - data_train: data used to train k-NN classifier and perform classifier on\n",
        "      - data_test: data set of which labels will be predicted using the k-NN algorithm\n",
        "      - stage_train: true labels of train data set\n",
        "      - stage_test: true labels of test data set\n",
        "    Output is:\n",
        "      - knn: a classifier with optimized hyperparameters trained on the train data set\n",
        "      - acc_train: the accuracy of the optimized classifier on the trainig data\n",
        "      - acc_test: the accuracy of the optimized classifier on the testing data\n",
        "      - auc_test: the area under the curve of the optimized classifier on the testing data\n",
        "      - sens: the sensitivity of the optimized classifier on the testing data\n",
        "      - spec: the specificity of the optimized classifier on the testing data\n",
        "    \"\"\"\n",
        "\n",
        "    # Hyperparameters optimization \n",
        "    n_n = list(range(1,30))\n",
        "    # weights = ['uniform', 'distance']\n",
        "    leaf_size = list(range(1,50))\n",
        "    # p=[1,2]\n",
        "    hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_n)\n",
        "    knn_tune = neighbors.KNeighborsClassifier()\n",
        "    clf_tune_knn = model_selection.RandomizedSearchCV(knn_tune, hyperparameters, n_iter = 30, cv=5)\n",
        "    best_model = clf_tune_knn.fit(data_train, stage_train)\n",
        "    n_n_best = best_model.best_estimator_.get_params()['n_neighbors']\n",
        "    # weights_best = best_model.best_estimator_.get_params()['weights']\n",
        "    leaf_size_best = best_model.best_estimator_.get_params()['leaf_size']\n",
        "    # p_best = best_model.best_estimator_.get_params()['p']\n",
        "    \n",
        "    # Trainnig classifier on train data\n",
        "    knn = neighbors.KNeighborsClassifier(leaf_size=leaf_size_best, n_neighbors=n_n_best)\n",
        "    knn.fit(data_train, stage_train)\n",
        "\n",
        "    # Predicting labels of train and test data using the trained classifier\n",
        "    label_train_knn = knn.predict(data_train)\n",
        "    label_test_knn = knn.predict(data_test)\n",
        "    \n",
        "    # Performance\n",
        "    acc_train = knn.score(data_train, stage_train)\n",
        "    acc_test = knn.score(data_test, stage_test)\n",
        "    # Calculating confusion matrix\n",
        "    cm = metrics.confusion_matrix(stage_test, label_test_knn)\n",
        "    TP = cm[1][1]\n",
        "    TN = cm[0][0]\n",
        "    FP = cm[0][1]\n",
        "    FN = cm[1][0]\n",
        "    sens = (TP / float(TP+FN))\n",
        "    spec = (TN / float(TN + FP))\n",
        "    \n",
        "    # Try - except to prevent error during running with small test sizes\n",
        "    try:\n",
        "        auc_test = metrics.roc_auc_score(label_test_knn, stage_test)\n",
        "    except ValueError:\n",
        "        auc_test = float(\"NaN\")\n",
        "\n",
        "    # Return optimised classifier, accuracy calculated on the train set, accuracy calculated on the test set, auc calculated on the test set, sensitivity calculated on the test set, specificity calculated on the test set \n",
        "    return knn, acc_train, acc_test, auc_test, sens, spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD8nbCaz_XQy",
        "colab_type": "text"
      },
      "source": [
        "SVM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIbwSi_x_ODV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm_class(data_train, data_test, stage_train, stage_test):\n",
        "    \"\"\"\n",
        "    Function for performing the SVM classifier\n",
        "    and optimization of the SVM algorithm hyperparameters:\n",
        "      - kernel\n",
        "      - C\n",
        "      - degree\n",
        "    input:\n",
        "      - data_train: data used to train SVM classifier and perform classifier on\n",
        "      - data_test: data set of which labels will be predicted using the SVM algorithm\n",
        "      - stage_train: true labels of train data set\n",
        "      - stage_test: true labels of test data set\n",
        "    Output is:\n",
        "      - svc: a classifier with optimized hyperparameters trained on the train data set\n",
        "      - acc_train: the accuracy of the optimized classifier on the trainig data\n",
        "      - acc_test: the accuracy of the optimized classifier on the testing data\n",
        "      - auc_test: the area under the curve of the optimized classifier on the testing data\n",
        "      - sens: the sensitivity of the optimized classifier on the testing data\n",
        "      - spec: the specificity of the optimized classifier on the testing data\n",
        "     \"\"\"\n",
        "    # Hyperparameter optimization\n",
        "    kernels = ['linear', 'poly', 'rbf']\n",
        "    # gammas = [0.1, 1, 10, 100]\n",
        "    cs = [0.1, 1, 10, 100, 1000]\n",
        "    degrees = [0, 1, 2, 3, 4, 5, 6] # use only for 'poly'\n",
        "    hyperparameters = dict(kernel = kernels, C = cs, degree = degrees)\n",
        "    svm_tune = svm.SVC()\n",
        "    clf_tune_svm = model_selection.RandomizedSearchCV(svm_tune, hyperparameters, n_iter = 30, cv = 5)\n",
        "    best_model_svm = clf_tune_svm.fit(data_train,stage_train)\n",
        "    kernel_best = best_model_svm.best_estimator_.get_params()['kernel']\n",
        "    # gamma_best  = best_model_svm.best_estimator_.get_params()['gamma']\n",
        "    C_best = best_model_svm.best_estimator_.get_params()['C']\n",
        "    degree_best = best_model_svm.best_estimator_.get_params()['degree']\n",
        "    \n",
        "    # Trainnig classifier on train data\n",
        "    svc = svm.SVC(C=C_best, kernel=kernel_best, degree=degree_best)\n",
        "    svc.fit(data_train, stage_train)\n",
        "\n",
        "    # Predicting labels of train and test data using the trained classifier\n",
        "    label_train_svm = svc.predict(data_train)\n",
        "    label_test_svm= svc.predict(data_test)\n",
        "    \n",
        "    # Performance\n",
        "    acc_train = svc.score(data_train, stage_train)\n",
        "    acc_test = svc.score(data_test, stage_test)\n",
        "    # Calculating confusion matrix\n",
        "    cm = metrics.confusion_matrix(stage_test, label_test_svm)\n",
        "    TP = cm[1][1]\n",
        "    TN = cm[0][0]\n",
        "    FP = cm[0][1]\n",
        "    FN = cm[1][0]\n",
        "    sens = (TP / float(TP+FN))\n",
        "    spec = (TN / float(TN + FP))\n",
        "    \n",
        "    # Try - except to prevent error during running with small test sizes\n",
        "    try:\n",
        "        auc_test = metrics.roc_auc_score(label_test_svm, stage_test)\n",
        "    except ValueError:\n",
        "        auc_test = float(\"NaN\")\n",
        "    \n",
        "    # Return optimised classifier, accuracy calculated on the train set, accuracy calculated on the test set, auc calculated on the test set, sensitivity calculated on the test set, specificity calculated on the test set \n",
        "    return svc, acc_train, acc_test, auc_test, sens, spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-35ahwqXNmBZ",
        "colab_type": "text"
      },
      "source": [
        "RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tl-R6VRNoOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rf_class(data_train, data_test, stage_train, stage_test):\n",
        "    \"\"\"\n",
        "    Function for performing the RF classifier\n",
        "    and optimization of the RF algorithm hyperparameters:\n",
        "      - n_estimators\n",
        "      - min_sample_split\n",
        "      - min_samples_leaf\n",
        "    input:\n",
        "      - data_train: data used to train RF classifier and perform classifier on\n",
        "      - data_test: data set of which labels will be predicted using the RF algorithm\n",
        "      - stage_train: true labels of train data set\n",
        "      - stage_test: true labels of test data set\n",
        "    Output is:\n",
        "      - rfc: a classifier with optimized hyperparameters trained on the train data set\n",
        "      - acc_train: the accuracy of the optimized classifier on the trainig data\n",
        "      - acc_test: the accuracy of the optimized classifier on the testing data\n",
        "      - auc_test: the area under the curve of the optimized classifier on the testing data\n",
        "      - sens: the sensitivity of the optimized classifier on the testing data\n",
        "      - spec: the specificity of the optimized classifier on the testing data\n",
        "    \"\"\"\n",
        "\n",
        "    # Hyperparameters optimization \n",
        "    n_estimators = [10, 30, 50, 100, 300]                  \n",
        "    min_samples_split = [2, 7, 10, 12, 20]      \n",
        "    min_samples_leaf = [3, 5, 10, 15, 20]             \n",
        "    hyperparameters_rfc = dict(n_estimators=n_estimators, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n",
        "    rfc_tune = RandomForestClassifier()\n",
        "    clf_tune_rfc = model_selection.RandomizedSearchCV(rfc_tune, hyperparameters_rfc, n_iter = 30, cv=5)\n",
        "    best_model = clf_tune_rfc.fit(data_train, stage_train)\n",
        "    n_estimators_best = best_model.best_estimator_.get_params()['n_estimators']\n",
        "    min_samples_split_best = best_model.best_estimator_.get_params()['min_samples_split']\n",
        "    min_samples_leaf_best = best_model.best_estimator_.get_params()['min_samples_leaf']\n",
        "\n",
        "    # Trainnig classifier on train data\n",
        "    rfc = RandomForestClassifier(n_estimators=n_estimators_best, min_samples_split = min_samples_split_best, min_samples_leaf = min_samples_leaf_best)\n",
        "    rfc.fit(data_train, stage_train)\n",
        "    \n",
        "    # Predicting labels of train and test data using the trained classifier\n",
        "    label_train_rfc = rfc.predict(data_train)\n",
        "    label_test_rfc = rfc.predict(data_test)\n",
        "    \n",
        "    # Performance\n",
        "    acc_train = rfc.score(data_train, stage_train)\n",
        "    acc_test = rfc.score(data_test, stage_test)\n",
        "    # Calculating confusion matrix\n",
        "    cm = metrics.confusion_matrix(stage_test, label_test_rfc)\n",
        "    TP = cm[1][1]\n",
        "    TN = cm[0][0]\n",
        "    FP = cm[0][1]\n",
        "    FN = cm[1][0]\n",
        "    sens = (TP / float(TP+FN))\n",
        "    spec = (TN / float(TN + FP))\n",
        "    \n",
        "    # Try - except to prevent error during running with small test sizes\n",
        "    try:\n",
        "        auc_test = metrics.roc_auc_score(label_test_rfc, stage_test)\n",
        "    except ValueError:\n",
        "        auc_test = float(\"NaN\")\n",
        "    \n",
        "    # Return optimised classifier, accuracy calculated on the train set, accuracy calculated on the test set, auc calculated on the test set, sensitivity calculated on the test set, specificity calculated on the test set \n",
        "    return rfc, acc_train, acc_test, auc_test, sens, spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TevEkooxEcZ",
        "colab_type": "text"
      },
      "source": [
        "NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOvYRiiTxWVL",
        "colab_type": "code",
        "outputId": "a6108fe2-d1f2-412a-969d-9562e116ca8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def nn_class(data_train, data_test, stage_train, stage_test):\n",
        "    \"\"\"\n",
        "    Function for performing the NN classifier\n",
        "    and optimization of the NN algorithm hyperparameters:\n",
        "      - activation\n",
        "      - solver\n",
        "    input:\n",
        "      - data_train: data used to train NN classifier and perform classifier on\n",
        "      - data_test: data set of which labels will be predicted using the NN algorithm\n",
        "      - stage_train: true labels of train data set\n",
        "      - stage_test: true labels of test data set\n",
        "    Output is:\n",
        "      - nn: a classifier with optimized hyperparameters trained on the train data set\n",
        "      - acc_train: the accuracy of the optimized classifier on the trainig data\n",
        "      - acc_test: the accuracy of the optimized classifier on the testing data\n",
        "      - auc_test: the area under the curve of the optimized classifier on the testing data\n",
        "      - sens: the sensitivity of the optimized classifier on the testing data\n",
        "      - spec: the specificity of the optimized classifier on the testing data\n",
        "    \"\"\"\n",
        "\n",
        "    # Hyperparameters optimization \n",
        "    # hidden_layer_sizes = [(50,50,50), (50,100,50), (100,)]\n",
        "    # batch_size = [5, 10, 15, 20, 25]                 \n",
        "    activation = ['tanh', 'relu','identity', 'logistic'] \n",
        "    solver = ['lbfgs', 'sgd', 'adam']           \n",
        "    hyperparameters_nn = dict(solver = solver, activation = activation)\n",
        "    nn_tune = MLPClassifier()\n",
        "    clf_tune_nn = model_selection.RandomizedSearchCV(nn_tune, hyperparameters_nn, n_iter = 15, cv=5)\n",
        "    best_model = clf_tune_nn.fit(data_train, stage_train)\n",
        "    # hidden_layer_sizes_best = best_model.best_estimator_.get_params()['hidden_layer_sizes']\n",
        "    # batch_size_best = best_model.best_estimator_.get_params()['batch_size']\n",
        "    activation_best = best_model.best_estimator_.get_params()['activation']\n",
        "    solver_best = best_model.best_estimator_.get_params()['solver']\n",
        "    \n",
        "    # Trainnig classifier on train data\n",
        "    nn = MLPClassifier(solver = solver_best, activation = activation_best)\n",
        "    nn.fit(data_train, stage_train)\n",
        "\n",
        "    # Predicting labels of train and test data using the trained classifier\n",
        "    label_train_nn = nn.predict(data_train)\n",
        "    label_test_nn = nn.predict(data_test)\n",
        "    \n",
        "    # Performance\n",
        "    acc_train_nn = nn.score(data_train, stage_train)\n",
        "    acc_test_nn = nn.score(data_test, stage_test)\n",
        "    # Calculating confusion matrix\n",
        "    cm = metrics.confusion_matrix(stage_test, label_test_nn)\n",
        "    TP = cm[1][1]\n",
        "    TN = cm[0][0]\n",
        "    FP = cm[0][1]\n",
        "    FN = cm[1][0]\n",
        "    sens = (TP / float(TP+FN))\n",
        "    spec = (TN / float(TN + FP))\n",
        "    \n",
        "    # Try - except to prevent error during running with small test sizes\n",
        "    try:\n",
        "        auc_test = metrics.roc_auc_score(label_test_nn, stage_test)\n",
        "    except ValueError:\n",
        "        auc_test = float(\"NaN\")\n",
        "\n",
        "    # Return optimised classifier, accuracy calculated on the train set, accuracy calculated on the test set, auc calculated on the test set, sensitivity calculated on the test set, specificity calculated on the test set   \n",
        "    return nn, acc_train_nn, acc_test_nn, auc_test, sens, spec\n",
        "\n",
        "print('Conclusion: running the neural network gave an warning concerning it does not converge after 200 iterations and because of this warning the decision was made to not further explore this option')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conclusion: running the neural network gave an warning concerning it does not converge after 200 iterations and because of this warning the decision was made to not further explore this option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZcHSCFrWSBm",
        "colab_type": "text"
      },
      "source": [
        "## Functions used in Outer and inner loop to evaluate performance model\n",
        "- Function to execute the correct feature selection method on train and test data\n",
        "- Function to determine the names of the feature selection method and classifier that were used in the best model\n",
        "- Function to apply classifier from the best model to train and test data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63UK5AoDUTAZ",
        "colab_type": "text"
      },
      "source": [
        "Function to execute the correct feature selection method on train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHoqzGY6Tp2N",
        "colab": {}
      },
      "source": [
        "def best_selector(train, test, stage_train, selector):\n",
        "    \"\"\"\n",
        "    Function which decides which selector to apply to the outer data and test set\n",
        "    Input:\n",
        "    - Train: the train data on which the selector should be applied\n",
        "    - Test: the test data on which the selector should be applied\n",
        "    - Stage_train: the labels of the train data\n",
        "    - Selector: the name of selector used according to the variable selector_used\n",
        "    Output: \n",
        "    - Train_out: the train data transformed by the selector\n",
        "    - Test_out: the test data transformed by the selector\n",
        "    \"\"\"\n",
        "    if selector_used == 'Univariate':\n",
        "        selector_train_out, selector_test_out = uni(train, test, stage_train, 60)\n",
        "    elif selector_used == 'PCA':\n",
        "        selector_train_out, selector_test_out = pca_opt(train, test)\n",
        "    elif selector == 'Univariate and PCA':\n",
        "        selector_train_out_uni, selector_test_out_uni = uni(train, test, stage_train, 60)\n",
        "        selector_train_out, selector_test_out = pca_opt(selector_train_out_uni, selector_test_out_uni)\n",
        "    else:\n",
        "        print('no feature selection method was found according to given selector')\n",
        "    return selector_train_out, selector_test_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKJaC0mRjJk",
        "colab_type": "text"
      },
      "source": [
        "Function to determine the names of the feature selection method and classifier that were used in the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9xl3w76RjWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def name_best_model(index):\n",
        "    \"\"\"\n",
        "    Function to determine the names of the feature selection method and classifier that were used in the best model\n",
        "    Input:\n",
        "    - Index: index from which names feature selection method and classifier of the best model can be derived\n",
        "    Output: \n",
        "    - selector_used: name of the feature selection method that is used in the best model\n",
        "    - classifier_used: name of the classifier that is used in the best model\n",
        "    \"\"\"\n",
        "    if index == 0:\n",
        "        selector_used = 'Univariate'\n",
        "        classifier_used = 'k-NN'\n",
        "    elif index == 1:\n",
        "        selector_used = 'PCA'\n",
        "        classifier_used = 'k-NN'\n",
        "    elif index == 2:\n",
        "        selector_used = 'Univariate and PCA'\n",
        "        classifier_used = 'k-NN'\n",
        "    elif index == 3:\n",
        "        selector_used = 'Univariate'\n",
        "        classifier_used = 'SVM'\n",
        "    elif index == 4:\n",
        "        selector_used = 'PCA'\n",
        "        classifier_used = 'SVM'\n",
        "    elif index == 5:\n",
        "        selector_used = 'Univariate and PCA'\n",
        "        classifier_used = 'SVM'\n",
        "    elif index == 6:\n",
        "        selector_used = 'Univariate'\n",
        "        classifier_used = 'RF'\n",
        "    elif index == 7:\n",
        "        selector_used = 'PCA'\n",
        "        classifier_used = 'RF'\n",
        "    elif index == 8:\n",
        "        selector_used = 'Univariate and PCA'\n",
        "        classifier_used = 'RF'\n",
        "    else:\n",
        "        selector_used ='No selector could be selected based on given index'\n",
        "        classifier_used = 'No classifier could be selected based on given index'\n",
        "    return selector_used, classifier_used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd1o9GmkXTqN",
        "colab_type": "text"
      },
      "source": [
        "Function to apply classifier from the best model to train and test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z9iB9PKXTz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_classifier(train, test, stage_train, stage_test, classifier_used):\n",
        "    \"\"\"\n",
        "    Function to apply classifier from the best model to train and test data \n",
        "    Input:\n",
        "    - Index: index from which names feature selection method and classifier of the best model can be derived\n",
        "    Output: \n",
        "    - selector_used: name of the feature selection method that is used in the best model\n",
        "    - classifier_used: name of the classifier that is used in the best model\n",
        "    \"\"\"\n",
        "    if classifier_used == 'k-NN':\n",
        "        clf, acc_train, acc_test, auc_test, sens, spec = knn_class(train, test, stage_train, stage_test)\n",
        "    elif classifier_used == 'SVM':\n",
        "        clf, acc_train, acc_test, auc_test, sens, spec = svm_class(train, test, stage_train, stage_test)\n",
        "    elif classifier_used == 'RF':\n",
        "        clf, acc_train, acc_test, auc_test, sens, spec = rf_class(train, test, stage_train, stage_test)\n",
        "    else:\n",
        "        print('No classifier was found according to classifier_used')\n",
        "    return clf, acc_train, acc_test, auc_test, sens, spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWrbhphALMNQ",
        "colab_type": "text"
      },
      "source": [
        "## Outer and inner loop to evaluate performance model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XzhS505LMgV",
        "colab_type": "code",
        "outputId": "82edcd6f-f4b9-488e-9ceb-3daba6d94377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Defining data and stage\n",
        "stage = data_start['label']\n",
        "data = data_start.drop(columns='label')\n",
        "stage = preprocessing.label_binarize(stage, ['T12', 'T34'] )\n",
        "stage = [i[0] for i in stage]\n",
        "pd.options.mode.chained_assignment = None  \n",
        "\n",
        "# splitting in train- and test\n",
        "n_split_outer = 50 # number of outer loop iterations\n",
        "n_split_inner = 10 # number of inner loop iterations\n",
        "cv_fold_outer = model_selection.StratifiedShuffleSplit(n_splits = n_split_outer, test_size=0.2, random_state=42)\n",
        "cv_fold_inner = model_selection.StratifiedKFold(n_splits = n_split_inner) \n",
        "\n",
        "# creating empty lists\n",
        "acc_total = []\n",
        "auc_total = []\n",
        "sensitivity_total = []\n",
        "specificity_total =[]\n",
        "\n",
        "# Initialize counters\n",
        "count_k_uni = 0\n",
        "count_k_pca = 0\n",
        "count_k_uni_pca = 0\n",
        "count_s_uni = 0\n",
        "count_s_pca = 0\n",
        "count_s_uni_pca = 0\n",
        "count_r_uni = 0\n",
        "count_r_pca = 0\n",
        "count_r_uni_pca = 0\n",
        "\n",
        "# Outer loop to check performance of the model.\n",
        "# 50x times the best model from the inner loop is trained on the outer train data and the labels of the test data are predicted.\n",
        "# This will result in performance measures 50 times, averaging over these values will give the performance of the model.\n",
        "for train_index, test_index in cv_fold_outer.split(data, stage):\n",
        "    stage = np.array(stage)\n",
        "    outer_train = data.iloc[train_index] \n",
        "    outer_stage_train = stage[train_index]\n",
        "    outer_test = data.iloc[test_index]\n",
        "    outer_stage_test = stage[test_index]\n",
        "\n",
        "    acc_knn_uni = []\n",
        "    acc_knn_pca = []\n",
        "    acc_knn_uni_pca = []\n",
        "    acc_svm_uni = []\n",
        "    acc_svm_pca = []\n",
        "    acc_svm_uni_pca = []\n",
        "    acc_rf_uni = []\n",
        "    acc_rf_pca = []\n",
        "    acc_rf_uni_pca = []\n",
        "    \n",
        "    # Inner loop to choose the best combination of feature selection method and classifier. \n",
        "    # 10 times a new model is created an tested on the validation set. \n",
        "    # The model with the highest mean accuracy on the validation set is selected as model to use in the outer loop.\n",
        "    # Possible feature selection methods: univariate feature selection, PCA, combination of univariate feature selection and PCA\n",
        "    # Possible classifiers: k-NN, SVM, RF, (NN)\n",
        "    for train_index, val_index in cv_fold_inner.split(outer_train, outer_stage_train): \n",
        "        \n",
        "        inner_train = outer_train.iloc[train_index] \n",
        "        inner_stage_train = outer_stage_train[train_index]\n",
        "        inner_val = outer_train.iloc[val_index]\n",
        "        inner_stage_val = outer_stage_train[val_index]\n",
        "        \n",
        "        # Remove columns from dataframes\n",
        "        inner_train, inner_val = data_cleaning(inner_train, inner_val)\n",
        "        \n",
        "        # Data scaling\n",
        "        inner_train, inner_val = data_scaling(inner_train, inner_val)\n",
        "\n",
        "        # Univariate Feature Selection\n",
        "        inner_train_uni, inner_val_uni = uni(inner_train, inner_val, inner_stage_train, 20)\n",
        "\n",
        "        # PCA\n",
        "        inner_train_pca, inner_val_pca = pca_opt(inner_train, inner_val)\n",
        "\n",
        "        # Univariate Feature Selection + PCA\n",
        "        inner_train_uni_p, inner_val_uni_p = uni(inner_train, inner_val, inner_stage_train, 80)\n",
        "        inner_train_uni_pca, inner_val_uni_pca = pca_opt(inner_train_uni_p, inner_val_uni_p)\n",
        "\n",
        "        # option 1: Uni + k-NN\n",
        "        clf_k_uni, acc_train_k_uni, acc_val_k_uni, auc_val_k_uni, sens_k_uni, spec_k_uni = knn_class(inner_train_uni, inner_val_uni, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # option 2: PCA + k-NN\n",
        "        clf_k_pca, acc_train_k_pca, acc_val_k_pca, auc_val_k_pca, sens_k_pca, spec_k_pca = knn_class(inner_train_pca, inner_val_pca, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # option 3: Uni and PCA + k-NN\n",
        "        clf_k_uni_pca, acc_train_k_uni_pca, acc_val_k_uni_pca, auc_val_k_uni_pca, sens_k_uni_pca, spec_k_uni_pca = knn_class(inner_train_uni_pca, inner_val_uni_pca, inner_stage_train, inner_stage_val) \n",
        "\n",
        "        # option 4: Uni + SVM\n",
        "        clf_s_uni, acc_train_s_uni, acc_val_s_uni, auc_val_s_uni, sens_s_uni, spec_s_uni = svm_class(inner_train_uni, inner_val_uni, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # option 5: PCA + SVM\n",
        "        clf_s_pca, acc_train_s_pca, acc_val_s_pca, auc_val_s_pca, sens_s_pca, spec_s_pca = svm_class(inner_train_pca, inner_val_pca, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # option 6: Uni and PCA + SVM\n",
        "        clf_s_uni_pca, acc_train_s_uni_pca, acc_val_s_uni_pca, auc_val_s_uni_pca, sens_s_uni_pca, spec_s_uni_pca = svm_class(inner_train_uni_pca, inner_val_uni_pca, inner_stage_train, inner_stage_val)   \n",
        "\n",
        "        # option 7: Uni + RF\n",
        "        clf_r_uni, acc_train_r_uni, acc_val_r_uni, auc_val_r_uni, sens_r_uni, spec_r_uni = rf_class(inner_train_uni, inner_val_uni, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # option 8: PCA + RF\n",
        "        clf_r_pca, acc_train_r_pca, acc_val_r_pca, auc_val_r_pca, sens_r_pca, spec_r_pca = rf_class(inner_train_pca, inner_val_pca, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # option 9: Uni and PCA + RF\n",
        "        clf_r_uni_pca, acc_train_r_uni_pca, acc_val_r_uni_pca, auc_val_r_uni_pca, sens_r_uni_pca, spec_r_uni_pca = rf_class(inner_train_uni_pca, inner_val_uni_pca, inner_stage_train, inner_stage_val)\n",
        "\n",
        "        # k-NN\n",
        "        acc_knn_uni.append(acc_val_k_uni)\n",
        "        acc_knn_pca.append(acc_val_k_pca)\n",
        "        acc_knn_uni_pca.append(acc_val_k_uni_pca)\n",
        "\n",
        "        # SVM\n",
        "        acc_svm_uni.append(acc_val_s_uni)\n",
        "        acc_svm_pca.append(acc_val_s_pca)\n",
        "        acc_svm_uni_pca.append(acc_val_s_uni_pca)\n",
        "\n",
        "        # RF\n",
        "        acc_rf_uni.append(acc_val_r_uni)\n",
        "        acc_rf_pca.append(acc_val_r_pca)\n",
        "        acc_rf_uni_pca.append(acc_val_r_uni_pca)\n",
        "\n",
        "    # calculate mean + take best mean\n",
        "    all_acc_together = [mean(acc_knn_uni), mean(acc_knn_pca), mean(acc_knn_uni_pca),\n",
        "                        mean(acc_svm_uni), mean(acc_svm_pca), mean(acc_svm_uni_pca),\n",
        "                        mean(acc_rf_uni), mean(acc_rf_pca), mean(acc_rf_uni_pca)]\n",
        "    best_mean_model = max(all_acc_together)\n",
        "    index_best_mean_model = all_acc_together.index(best_mean_model)\n",
        "    selector_used, classifier_used = name_best_model(index_best_mean_model)\n",
        "\n",
        "    print(f'The feature selector used is: {selector_used}')\n",
        "    print(f'The classifier used is: {classifier_used}')\n",
        "    \n",
        "    # Remove columns from dataframes\n",
        "    outer_train, outer_test = data_cleaning(outer_train, outer_test)\n",
        "        \n",
        "    # Data scaling\n",
        "    outer_train, outer_test = data_scaling(outer_train, outer_test)\n",
        "\n",
        "    # Feature Selection\n",
        "    outer_train, outer_test = best_selector(outer_train, outer_test, stage_train, selector_used)\n",
        "\n",
        "    # Classifier\n",
        "    clf, acc_train, acc_test, auc_test, sensitivity, specificity = best_classifier(outer_train, outer_test, outer_stage_train, outer_stage_test, classifier_used)\n",
        "    \n",
        "    # Performance measures\n",
        "    acc_total.append(acc_test)\n",
        "    auc_total.append(auc_test)\n",
        "    sensitivity_total.append(sensitivity)\n",
        "    specificity_total.append(specificity)\n",
        "    \n",
        "    # Count how often which model is choosen\n",
        "    if selector_used == 'Univariate' and classifier_used == 'k-NN':\n",
        "        count_k_uni += 1\n",
        "    elif selector_used == 'PCA' and classifier_used == 'k-NN':\n",
        "        count_k_pca += 1\n",
        "    elif selector_used == 'Univariate and PCA' and classifier_used == 'k-NN':\n",
        "        count_k_uni_pca += 1\n",
        "    elif selector_used == 'Univariate' and classifier_used == 'SVM':\n",
        "        count_s_uni += 1\n",
        "    elif selector_used == 'PCA' and classifier_used == 'SVM':\n",
        "        count_s_pca += 1\n",
        "    elif selector_used == 'Univariate and PCA' and classifier_used == 'SVM':\n",
        "        count_s_uni_pca += 1\n",
        "    elif selector_used == 'Univariate' and classifier_used == 'RF':\n",
        "        count_r_uni += 1\n",
        "    elif selector_used == 'PCA' and classifier_used == 'RF':\n",
        "        count_r_pca += 1\n",
        "    elif selector_used == 'Univariate and PCA' and classifier_used == 'RF':\n",
        "        count_r_uni_pca += 1\n",
        "\n",
        "# printing the results of the performance of the model\n",
        "print(f'\\nThe results of running the outer loop {n_split_outer}x times and the inner loop {n_split_inner}x times are: \\n')\n",
        "\n",
        "print(f'The mean accuracy of the model is: {round(mean(acc_total), 3)}')  \n",
        "print(f'The standard deviation of the accuracy of the model is: {round(stdev(acc_total), 3)}')\n",
        "print(f'The standard error of the accuracy of the model is: {round(stdev(acc_total)/sqrt(n_split_outer),3)}')\n",
        "\n",
        "print(f'\\nThe mean AUC of a the model is: {round(mean(auc_total), 3)}')   \n",
        "print(f'The standard deviation of the AUC of the model is: {round(stdev(auc_total), 3)}')\n",
        "print(f'The standard error of the AUC of the model is: {round(stdev(auc_total)/sqrt(n_split_outer),3)}')\n",
        "\n",
        "print(f'\\nThe mean sensitivity of the model is: {round(mean(sensitivity_total),3)}')\n",
        "print(f'The standard deviation of the sensitivity of the model is: {round(stdev(sensitivity_total), 3)}')\n",
        "print(f'The standard error of the sensitivity of the model is: {round(stdev(sensitivity_total)/sqrt(n_split_outer),3)}')\n",
        "\n",
        "print(f'\\nThe mean specificity of the model is: {round(mean(specificity_total),3)}')\n",
        "print(f'The standard deviation of the specificity of the model is: {round(stdev(specificity_total), 3)}')\n",
        "print(f'The standard error of the specificity of the model is: {round(stdev(specificity_total)/sqrt(n_split_outer),3)}')\n",
        "\n",
        "print(f'\\nThe combination of univariate feature selection and k-NN was chosen as the optimal model in: {count_k_uni}/{n_split_outer}')\n",
        "print(f'The combination of PCA and k-NN was chosen as the optimal model in: {count_k_pca}/{n_split_outer}')\n",
        "print(f'The combination of univariate feature selection, PCA and k-NN was chosen as the optimal model in: {count_k_uni_pca}/{n_split_outer}')\n",
        "\n",
        "print(f'\\nThe combination of univariate feature selection and SVM was chosen as the optimal model in: {count_s_uni}/{n_split_outer}')\n",
        "print(f'The combination of PCA and SVM was chosen as the optimal model in: {count_s_pca}/{n_split_outer}')\n",
        "print(f'The combination of univariate feature selection, PCA and SVM was chosen as the optimal model in: {count_s_uni_pca}/{n_split_outer}')\n",
        "\n",
        "print(f'\\nThe combination of univariate feature selection and RF was chosen as the optimal model in: {count_r_uni}/{n_split_outer}')\n",
        "print(f'The combination of PCA and RF was chosen as the optimal model in: {count_r_pca}/{n_split_outer}')\n",
        "print(f'The combination of univariate feature selection, PCA and RF was chosen as the optimal model in: {count_r_uni_pca}/{n_split_outer}')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-53cf12e579a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# option 8: PCA + RF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mclf_r_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_r_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val_r_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_val_r_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msens_r_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec_r_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_val_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_stage_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_stage_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# option 9: Uni and PCA + RF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-6c98af2d5be7>\u001b[0m in \u001b[0;36mrf_class\u001b[0;34m(data_train, data_test, stage_train, stage_test)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mrfc_tune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mclf_tune_rfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters_rfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_tune_rfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mn_estimators_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmin_samples_split_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_samples_split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                                       *args, **kwargs)\n\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    667\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[1;32m    668\u001b[0m                                             lock)\n\u001b[0;32m--> 669\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \"\"\"\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         attrs = [v for v in vars(estimator)\n\u001b[0m\u001b[1;32m    964\u001b[0m                  if v.endswith(\"_\") and not v.startswith(\"__\")]\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         attrs = [v for v in vars(estimator)\n\u001b[0;32m--> 964\u001b[0;31m                  if v.endswith(\"_\") and not v.startswith(\"__\")]\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}